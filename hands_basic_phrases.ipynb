{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e3db39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì∑ Starting capture in 3 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Dataset saved to C:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\BasicPhrasesSignLanguages\\good.csv\n",
      "üßÆ Frames processed: 369\n",
      "üíæ Valid samples collected: 261\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "# === Configuration ===\n",
    "DATA_DIR = r\"C:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\ASLBasicPhrasesSignLanguages\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "label = input(\"Good\").strip().lower()\n",
    "SAVE_PATH = os.path.join(DATA_DIR, f\"{label}.csv\")\n",
    "\n",
    "# === MediaPipe setup ===\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=2, \n",
    "    min_detection_confidence=0.7\n",
    ")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "data = []\n",
    "frame_count = 0\n",
    "saved_count = 0\n",
    "\n",
    "print(\"üì∑ Starting capture in 3 seconds...\")\n",
    "time.sleep(3)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, c = frame.shape\n",
    "    frame_count += 1\n",
    "\n",
    "    # Detect hands\n",
    "    results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # === If no hand detected ===\n",
    "    if not results.multi_hand_landmarks:\n",
    "        cv2.putText(frame, \"No hands detected!\", (10, 35),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.imshow(\"Two-Hand Capture\", frame)\n",
    "\n",
    "        # Skip saving this frame (no data collected)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        continue\n",
    "\n",
    "    # === If hand(s) detected, record landmarks ===\n",
    "    row = []\n",
    "    for hand_landmarks in results.multi_hand_landmarks:\n",
    "        for lm in hand_landmarks.landmark:\n",
    "            row.extend([lm.x, lm.y, lm.z])\n",
    "\n",
    "    # Pad second hand if only one hand detected\n",
    "    if len(results.multi_hand_landmarks) == 1:\n",
    "        row.extend([0] * (21 * 3))\n",
    "\n",
    "    row.append(label)\n",
    "    data.append(row)\n",
    "    saved_count += 1\n",
    "\n",
    "    # Draw hands on frame\n",
    "    for hand_landmarks in results.multi_hand_landmarks:\n",
    "        mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    cv2.putText(frame, f\"Collecting: {label}\", (10, 35),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Samples: {saved_count}\", (10, 70),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    cv2.imshow(\"Two-Hand Capture\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# === Save dataset ===\n",
    "columns = []\n",
    "for hand in [\"L1_\", \"L2_\"]:\n",
    "    for i in range(21):\n",
    "        columns += [f\"{hand}x{i}\", f\"{hand}y{i}\", f\"{hand}z{i}\"]\n",
    "columns.append(\"label\")\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "if not df.empty:\n",
    "    df.to_csv(SAVE_PATH, index=False)\n",
    "    print(f\"\\n‚úÖ Dataset saved to {SAVE_PATH}\")\n",
    "    print(f\"üßÆ Frames processed: {frame_count}\")\n",
    "    print(f\"üíæ Valid samples collected: {saved_count}\")\n",
    "else:\n",
    "    print(\"üö´ No valid samples collected (no hands detected). File not saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0816677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Found 6 dataset files\n",
      "‚úÖ Loaded combined_basic_phrases_dataset.csv (3624 samples)\n",
      "‚úÖ Loaded good.csv (261 samples)\n",
      "‚úÖ Loaded hello.csv (173 samples)\n",
      "‚úÖ Loaded hey.csv (244 samples)\n",
      "‚úÖ Loaded iloveyou.csv (214 samples)\n",
      "‚úÖ Loaded thankyou.csv (230 samples)\n",
      "\n",
      "‚úÖ Combined dataset created successfully!\n",
      "üìÑ Saved to: C:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\ASLBasicPhrasesSignLanguages\\combined_basic_phrases_dataset.csv\n",
      "üßÆ Total samples: 4746\n",
      "üè∑Ô∏è Labels: [nan 'thankyou' 'hello' 'iloveyou' 'good' 'Hey']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Folder containing your individual datasets\n",
    "DATA_DIR = r\"C:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\ASLBasicPhrasesSignLanguages\"\n",
    "\n",
    "# Find all CSV files (each phrase dataset)\n",
    "all_files = glob.glob(os.path.join(DATA_DIR, \"*.csv\"))\n",
    "print(f\"üìÅ Found {len(all_files)} dataset files\")\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for file in all_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        if df.empty:\n",
    "            print(f\"‚ö†Ô∏è Skipped empty file: {os.path.basename(file)}\")\n",
    "            continue\n",
    "        df_list.append(df)\n",
    "        print(f\"‚úÖ Loaded {os.path.basename(file)} ({df.shape[0]} samples)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading {os.path.basename(file)}: {e}\")\n",
    "\n",
    "# Merge them all together\n",
    "if df_list:\n",
    "    final_df = pd.concat(df_list, ignore_index=True)\n",
    "    combined_path = os.path.join(DATA_DIR, \"combined_basic_phrases_dataset.csv\")\n",
    "    final_df.to_csv(combined_path, index=False)\n",
    "\n",
    "    print(\"\\n‚úÖ Combined dataset created successfully!\")\n",
    "    print(f\"üìÑ Saved to: {combined_path}\")\n",
    "    print(\"üßÆ Total samples:\", final_df.shape[0])\n",
    "    print(\"üè∑Ô∏è Labels:\", final_df['label'].unique())\n",
    "else:\n",
    "    print(\"üö´ No valid datasets found to merge.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc2923a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for NaN values...\n",
      "‚ö†Ô∏è Found 598283 missing values ‚Äî cleaning dataset...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m y = df[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# üß™ Step 2: Split Data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m X_train, X_test, y_train, y_test = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\n\u001b[32m     29\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# üß† Step 3: Train Model\u001b[39;00m\n\u001b[32m     32\u001b[39m model = RandomForestClassifier(n_estimators=\u001b[32m200\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2919\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2916\u001b[39m arrays = indexable(*arrays)\n\u001b[32m   2918\u001b[39m n_samples = _num_samples(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m2919\u001b[39m n_train, n_test = \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.25\u001b[39;49m\n\u001b[32m   2921\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2923\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m   2924\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2499\u001b[39m, in \u001b[36m_validate_shuffle_split\u001b[39m\u001b[34m(n_samples, test_size, train_size, default_test_size)\u001b[39m\n\u001b[32m   2496\u001b[39m n_train, n_test = \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[32m   2498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_train == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2499\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2500\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maforementioned parameters.\u001b[39m\u001b[33m\"\u001b[39m.format(n_samples, test_size, train_size)\n\u001b[32m   2503\u001b[39m     )\n\u001b[32m   2505\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[31mValueError\u001b[39m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "DATA_PATH = r\"C:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\ASLBasicPhrasesSignLanguages\\combined_basic_phrases_dataset.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# üßπ Step 1: Clean Data\n",
    "print(\"Checking for NaN values...\")\n",
    "\n",
    "nan_counts = df.isna().sum().sum()\n",
    "if nan_counts > 0:\n",
    "    print(f\"‚ö†Ô∏è Found {nan_counts} missing values ‚Äî cleaning dataset...\")\n",
    "    df = df.dropna()\n",
    "else:\n",
    "    print(\"‚úÖ No missing values detected.\")\n",
    "\n",
    "# Ensure numeric values only\n",
    "X = df.drop('label', axis=1)\n",
    "X = X.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "\n",
    "y = df['label']\n",
    "\n",
    "# üß™ Step 2: Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# üß† Step 3: Train Model\n",
    "model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# üìä Step 4: Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"‚úÖ Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# üíæ Step 5: Save Model\n",
    "with open(\"basic_phrases_twohand_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(\"üíæ Model saved as 'basic_phrases_twohand_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "896ed895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load trained model\n",
    "with open(\"basic_phrases_twohand_model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.7)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        row = []\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                row.extend([lm.x, lm.y, lm.z])\n",
    "        if len(results.multi_hand_landmarks) == 1:\n",
    "            row.extend([0] * (21 * 3))\n",
    "        x = np.array(row).reshape(1, -1)\n",
    "        prediction = model.predict(x)\n",
    "        cv2.putText(frame, f\"{prediction[0]}\", (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3)\n",
    "\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    cv2.imshow(\"Prediction - Two Hands\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.9 (.venv)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

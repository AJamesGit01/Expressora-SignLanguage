{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e3db39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📷 Starting capture in 3 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Dataset saved to C:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\BasicPhrasesSignLanguages\\good.csv\n",
      "🧮 Frames processed: 369\n",
      "💾 Valid samples collected: 261\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "# === Configuration ===\n",
    "DATA_DIR = r\"C:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\ASLBasicPhrasesSignLanguages\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "label = input(\"Good\").strip().lower()\n",
    "SAVE_PATH = os.path.join(DATA_DIR, f\"{label}.csv\")\n",
    "\n",
    "# === MediaPipe setup ===\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=2, \n",
    "    min_detection_confidence=0.7\n",
    ")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "data = []\n",
    "frame_count = 0\n",
    "saved_count = 0\n",
    "\n",
    "print(\"📷 Starting capture in 3 seconds...\")\n",
    "time.sleep(3)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, c = frame.shape\n",
    "    frame_count += 1\n",
    "\n",
    "    # Detect hands\n",
    "    results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # === If no hand detected ===\n",
    "    if not results.multi_hand_landmarks:\n",
    "        cv2.putText(frame, \"No hands detected!\", (10, 35),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.imshow(\"Two-Hand Capture\", frame)\n",
    "\n",
    "        # Skip saving this frame (no data collected)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        continue\n",
    "\n",
    "    # === If hand(s) detected, record landmarks ===\n",
    "    row = []\n",
    "    for hand_landmarks in results.multi_hand_landmarks:\n",
    "        for lm in hand_landmarks.landmark:\n",
    "            row.extend([lm.x, lm.y, lm.z])\n",
    "\n",
    "    # Pad second hand if only one hand detected\n",
    "    if len(results.multi_hand_landmarks) == 1:\n",
    "        row.extend([0] * (21 * 3))\n",
    "\n",
    "    row.append(label)\n",
    "    data.append(row)\n",
    "    saved_count += 1\n",
    "\n",
    "    # Draw hands on frame\n",
    "    for hand_landmarks in results.multi_hand_landmarks:\n",
    "        mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    cv2.putText(frame, f\"Collecting: {label}\", (10, 35),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Samples: {saved_count}\", (10, 70),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    cv2.imshow(\"Two-Hand Capture\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# === Save dataset ===\n",
    "columns = []\n",
    "for hand in [\"L1_\", \"L2_\"]:\n",
    "    for i in range(21):\n",
    "        columns += [f\"{hand}x{i}\", f\"{hand}y{i}\", f\"{hand}z{i}\"]\n",
    "columns.append(\"label\")\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "if not df.empty:\n",
    "    df.to_csv(SAVE_PATH, index=False)\n",
    "    print(f\"\\n✅ Dataset saved to {SAVE_PATH}\")\n",
    "    print(f\"🧮 Frames processed: {frame_count}\")\n",
    "    print(f\"💾 Valid samples collected: {saved_count}\")\n",
    "else:\n",
    "    print(\"🚫 No valid samples collected (no hands detected). File not saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0816677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Found 6 dataset files\n",
      "✅ Loaded combined_basic_phrases_dataset.csv (3624 samples)\n",
      "✅ Loaded good.csv (261 samples)\n",
      "✅ Loaded hello.csv (173 samples)\n",
      "✅ Loaded hey.csv (244 samples)\n",
      "✅ Loaded iloveyou.csv (214 samples)\n",
      "✅ Loaded thankyou.csv (230 samples)\n",
      "\n",
      "✅ Combined dataset created successfully!\n",
      "📄 Saved to: C:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\ASLBasicPhrasesSignLanguages\\combined_basic_phrases_dataset.csv\n",
      "🧮 Total samples: 4746\n",
      "🏷️ Labels: [nan 'thankyou' 'hello' 'iloveyou' 'good' 'Hey']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Folder containing your individual datasets\n",
    "DATA_DIR = r\"C:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\ASLBasicPhrasesSignLanguages\"\n",
    "\n",
    "# Find all CSV files (each phrase dataset)\n",
    "all_files = glob.glob(os.path.join(DATA_DIR, \"*.csv\"))\n",
    "print(f\"📁 Found {len(all_files)} dataset files\")\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for file in all_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        if df.empty:\n",
    "            print(f\"⚠️ Skipped empty file: {os.path.basename(file)}\")\n",
    "            continue\n",
    "        df_list.append(df)\n",
    "        print(f\"✅ Loaded {os.path.basename(file)} ({df.shape[0]} samples)\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error reading {os.path.basename(file)}: {e}\")\n",
    "\n",
    "# Merge them all together\n",
    "if df_list:\n",
    "    final_df = pd.concat(df_list, ignore_index=True)\n",
    "    combined_path = os.path.join(DATA_DIR, \"combined_basic_phrases_dataset.csv\")\n",
    "    final_df.to_csv(combined_path, index=False)\n",
    "\n",
    "    print(\"\\n✅ Combined dataset created successfully!\")\n",
    "    print(f\"📄 Saved to: {combined_path}\")\n",
    "    print(\"🧮 Total samples:\", final_df.shape[0])\n",
    "    print(\"🏷️ Labels:\", final_df['label'].unique())\n",
    "else:\n",
    "    print(\"🚫 No valid datasets found to merge.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc2923a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for NaN values...\n",
      "⚠️ Found 598283 missing values — cleaning dataset...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m y = df[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# 🧪 Step 2: Split Data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m X_train, X_test, y_train, y_test = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\n\u001b[32m     29\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# 🧠 Step 3: Train Model\u001b[39;00m\n\u001b[32m     32\u001b[39m model = RandomForestClassifier(n_estimators=\u001b[32m200\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2919\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2916\u001b[39m arrays = indexable(*arrays)\n\u001b[32m   2918\u001b[39m n_samples = _num_samples(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m2919\u001b[39m n_train, n_test = \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.25\u001b[39;49m\n\u001b[32m   2921\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2923\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m   2924\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2499\u001b[39m, in \u001b[36m_validate_shuffle_split\u001b[39m\u001b[34m(n_samples, test_size, train_size, default_test_size)\u001b[39m\n\u001b[32m   2496\u001b[39m n_train, n_test = \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[32m   2498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_train == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2499\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2500\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maforementioned parameters.\u001b[39m\u001b[33m\"\u001b[39m.format(n_samples, test_size, train_size)\n\u001b[32m   2503\u001b[39m     )\n\u001b[32m   2505\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[31mValueError\u001b[39m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "DATA_PATH = r\"C:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\ASLBasicPhrasesSignLanguages\\combined_basic_phrases_dataset.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# 🧹 Step 1: Clean Data\n",
    "print(\"Checking for NaN values...\")\n",
    "\n",
    "nan_counts = df.isna().sum().sum()\n",
    "if nan_counts > 0:\n",
    "    print(f\"⚠️ Found {nan_counts} missing values — cleaning dataset...\")\n",
    "    df = df.dropna()\n",
    "else:\n",
    "    print(\"✅ No missing values detected.\")\n",
    "\n",
    "# Ensure numeric values only\n",
    "X = df.drop('label', axis=1)\n",
    "X = X.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "\n",
    "y = df['label']\n",
    "\n",
    "# 🧪 Step 2: Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 🧠 Step 3: Train Model\n",
    "model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 📊 Step 4: Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"✅ Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 💾 Step 5: Save Model\n",
    "with open(\"basic_phrases_twohand_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(\"💾 Model saved as 'basic_phrases_twohand_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "896ed895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "c:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load trained model\n",
    "with open(\"basic_phrases_twohand_model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.7)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        row = []\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                row.extend([lm.x, lm.y, lm.z])\n",
    "        if len(results.multi_hand_landmarks) == 1:\n",
    "            row.extend([0] * (21 * 3))\n",
    "        x = np.array(row).reshape(1, -1)\n",
    "        prediction = model.predict(x)\n",
    "        cv2.putText(frame, f\"{prediction[0]}\", (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3)\n",
    "\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    cv2.imshow(\"Prediction - Two Hands\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.9 (.venv)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
